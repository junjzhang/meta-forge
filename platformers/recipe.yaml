context:
  cuda: "12.4.0"
  version: 0.0.1
  name: "platformers"
  fa_git_url: https://github.com/Dao-AILab/flash-attention.git
  fa_git_tag: ${{ git.latest_tag( fa_git_url ) }}
  short_cuda: ${{ cuda[:-2] }}
  # short_cuda: ${{ cuda_compiler_version }}
  # fa_cuda_version: ${{  }}

package:
  name: ${{ name }}
  version: ${{ version }}

source:
  - path: ../../platformers/
    target_directory: platformers

  - git: https://github.com/Dao-AILab/flash-attention.git
    tag: ${{ fa_git_tag }}
    target_directory: flash_attn
  # - if: cuda=="12.4.0"
  #   then:
  #     url: https://pypi.python.org/packages/source/b/bsdiff4/bsdiff4-1.1.4.tar.gz
  # md5: 29f6089290505fc1a852e176bd276c42

  # - url: https://github.com/Dao-AILab/flash-attention/releases/download/v${{ fa_version }}/flash_attn-${{ fa_version }}
  #   sha256: 93441164c23b764d72c8a66d14b11d5bbd353ed6112ccf3b35efda2a98f9df02
  # tag: ${{ version }}

build:
  number: ${{ build|int + (microarch_level|int) * 100 }}
  # merge_build_and_host_envs: false
  script:
    content:
      - $PREFIX/bin/nvcc -V
      - cd flash_attn && ls
      # - $PYTHON -m pip install . -vvv --no-deps --no-build-isolation
      - $PYTHON setup.py install

    env:
      MAX_JOBS: ${{ CPU_COUNT }}
      TORCH_CUDA_ARCH_LIST: 8.0+PTX

  dynamic_linking:
    rpaths:
      - lib/
      - ${{ SP_DIR }}/torch/lib/

requirements:
  build:
    - ${{ compiler('c') }}
    - ${{ compiler('cxx') }}
    # - ${{ compiler('cuda') }}
    - ${{ stdlib('c') }}
    - ninja
  host:
    # - if: match(cuda, "12.4")
    #   then: pytorch::pytorch-cuda=12.4
    - packaging
    - pytorch::pytorch-cuda=${{ short_cuda }}
    - cuda
    - pytorch::pytorch
    - pytorch::torchaudio
    - pytorch::torchvision
    - python
    - pip
    - setuptools
# tests:
#   - python:
#       imports:
#         - fastuuid
